{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df257e7-62fc-45cc-81cf-a2e23c25e899",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "269a8125-7211-40b0-b0c9-452a8208c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f55d4b0c-00e6-4476-b959-6413e12db663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                           Version\n",
      "--------------------------------- --------------\n",
      "aiofiles                          24.1.0\n",
      "aiohappyeyeballs                  2.4.8\n",
      "aiohttp                           3.11.13\n",
      "aiosignal                         1.3.2\n",
      "airportsdata                      20250224\n",
      "annotated-types                   0.7.0\n",
      "anyio                             4.8.0\n",
      "appnope                           0.1.4\n",
      "argon2-cffi                       23.1.0\n",
      "argon2-cffi-bindings              21.2.0\n",
      "arrow                             1.3.0\n",
      "astor                             0.8.1\n",
      "asttokens                         3.0.0\n",
      "async-lru                         2.0.4\n",
      "attrs                             25.1.0\n",
      "babel                             2.17.0\n",
      "beautifulsoup4                    4.13.3\n",
      "blake3                            1.0.4\n",
      "bleach                            6.2.0\n",
      "certifi                           2024.8.30\n",
      "cffi                              1.17.1\n",
      "charset-normalizer                3.4.0\n",
      "click                             8.1.8\n",
      "cloudpickle                       3.1.1\n",
      "comm                              0.2.2\n",
      "compressed-tensors                0.9.1\n",
      "datasets                          3.3.2\n",
      "debugpy                           1.8.13\n",
      "decorator                         5.2.1\n",
      "defusedxml                        0.7.1\n",
      "depyf                             0.18.0\n",
      "dill                              0.3.8\n",
      "diskcache                         5.6.3\n",
      "distro                            1.9.0\n",
      "dnspython                         2.7.0\n",
      "einops                            0.8.1\n",
      "email_validator                   2.2.0\n",
      "executing                         2.2.0\n",
      "fastapi                           0.115.11\n",
      "fastapi-cli                       0.0.7\n",
      "fastjsonschema                    2.21.1\n",
      "filelock                          3.16.1\n",
      "fqdn                              1.5.1\n",
      "frozenlist                        1.5.0\n",
      "fsspec                            2024.10.0\n",
      "gguf                              0.10.0\n",
      "grpcio                            1.67.1\n",
      "h11                               0.14.0\n",
      "httpcore                          1.0.7\n",
      "httptools                         0.6.4\n",
      "httpx                             0.28.1\n",
      "huggingface-hub                   0.26.2\n",
      "idna                              3.10\n",
      "importlib_metadata                8.6.1\n",
      "interegular                       0.3.3\n",
      "ipykernel                         6.29.5\n",
      "ipython                           9.0.2\n",
      "ipython_pygments_lexers           1.1.1\n",
      "ipywidgets                        8.1.5\n",
      "isoduration                       20.11.0\n",
      "jedi                              0.19.2\n",
      "Jinja2                            3.1.6\n",
      "jiter                             0.9.0\n",
      "json5                             0.10.0\n",
      "jsonpointer                       3.0.0\n",
      "jsonschema                        4.23.0\n",
      "jsonschema-specifications         2024.10.1\n",
      "jupyter_client                    8.6.3\n",
      "jupyter_core                      5.7.2\n",
      "jupyter-events                    0.12.0\n",
      "jupyter-lsp                       2.2.5\n",
      "jupyter_server                    2.15.0\n",
      "jupyter_server_terminals          0.5.3\n",
      "jupyterlab                        4.3.5\n",
      "jupyterlab_pygments               0.3.0\n",
      "jupyterlab_server                 2.27.3\n",
      "jupyterlab_widgets                3.0.13\n",
      "lark                              1.2.2\n",
      "llama_cpp_python                  0.3.8\n",
      "llvmlite                          0.43.0\n",
      "lm-format-enforcer                0.10.11\n",
      "markdown-it-py                    3.0.0\n",
      "MarkupSafe                        3.0.2\n",
      "matplotlib-inline                 0.1.7\n",
      "mdurl                             0.1.2\n",
      "milvus-lite                       2.4.11\n",
      "mistral_common                    1.5.3\n",
      "mistune                           3.1.2\n",
      "mpmath                            1.3.0\n",
      "msgspec                           0.19.0\n",
      "multidict                         6.1.0\n",
      "multiprocess                      0.70.16\n",
      "nbclient                          0.10.2\n",
      "nbconvert                         7.16.6\n",
      "nbformat                          5.10.4\n",
      "nest-asyncio                      1.6.0\n",
      "networkx                          3.4.2\n",
      "notebook                          7.3.2\n",
      "notebook_shim                     0.2.4\n",
      "numba                             0.60.0\n",
      "numpy                             1.26.4\n",
      "openai                            1.66.3\n",
      "opencv-python-headless            4.11.0.86\n",
      "outlines                          0.1.11\n",
      "outlines_core                     0.1.26\n",
      "overrides                         7.7.0\n",
      "packaging                         24.2\n",
      "pandas                            2.2.3\n",
      "pandocfilters                     1.5.1\n",
      "parso                             0.8.4\n",
      "partial-json-parser               0.2.1.1.post5\n",
      "pexpect                           4.9.0\n",
      "pillow                            11.1.0\n",
      "pip                               24.2\n",
      "platformdirs                      4.3.6\n",
      "prometheus_client                 0.21.1\n",
      "prometheus-fastapi-instrumentator 7.0.2\n",
      "prompt_toolkit                    3.0.50\n",
      "propcache                         0.3.0\n",
      "protobuf                          4.25.5\n",
      "psutil                            7.0.0\n",
      "ptyprocess                        0.7.0\n",
      "pure_eval                         0.2.3\n",
      "py-cpuinfo                        9.0.0\n",
      "pyarrow                           19.0.1\n",
      "pycountry                         24.6.1\n",
      "pycparser                         2.22\n",
      "pydantic                          2.10.6\n",
      "pydantic_core                     2.27.2\n",
      "Pygments                          2.19.1\n",
      "pymilvus                          2.5.5\n",
      "python-dateutil                   2.9.0.post0\n",
      "python-dotenv                     1.0.1\n",
      "python-json-logger                3.3.0\n",
      "python-multipart                  0.0.20\n",
      "pytz                              2025.1\n",
      "PyYAML                            6.0.2\n",
      "pyzmq                             26.3.0\n",
      "referencing                       0.36.2\n",
      "regex                             2024.11.6\n",
      "requests                          2.32.3\n",
      "rfc3339-validator                 0.1.4\n",
      "rfc3986-validator                 0.1.1\n",
      "rich                              13.9.4\n",
      "rich-toolkit                      0.13.2\n",
      "rpds-py                           0.23.1\n",
      "safetensors                       0.4.5\n",
      "Send2Trash                        1.8.3\n",
      "sentencepiece                     0.2.0\n",
      "setuptools                        75.1.0\n",
      "shellingham                       1.5.4\n",
      "six                               1.17.0\n",
      "sniffio                           1.3.1\n",
      "soupsieve                         2.6\n",
      "stack-data                        0.6.3\n",
      "starlette                         0.46.1\n",
      "sympy                             1.13.1\n",
      "terminado                         0.18.1\n",
      "tiktoken                          0.9.0\n",
      "tinycss2                          1.4.0\n",
      "tokenizers                        0.21.0\n",
      "torch                             2.5.1\n",
      "torchaudio                        2.5.1\n",
      "torchvision                       0.20.1\n",
      "tornado                           6.4.2\n",
      "tqdm                              4.67.0\n",
      "traitlets                         5.14.3\n",
      "transformers                      4.49.0\n",
      "typer                             0.15.2\n",
      "types-python-dateutil             2.9.0.20241206\n",
      "typing_extensions                 4.12.2\n",
      "tzdata                            2025.1\n",
      "ujson                             5.10.0\n",
      "uri-template                      1.3.0\n",
      "urllib3                           2.2.3\n",
      "uvicorn                           0.34.0\n",
      "uvloop                            0.21.0\n",
      "vllm                              0.7.3\n",
      "watchfiles                        1.0.4\n",
      "wcwidth                           0.2.13\n",
      "webcolors                         24.11.1\n",
      "webencodings                      0.5.1\n",
      "websocket-client                  1.8.0\n",
      "websockets                        15.0.1\n",
      "wheel                             0.44.0\n",
      "widgetsnbextension                4.0.13\n",
      "xxhash                            3.5.0\n",
      "yarl                              1.18.3\n",
      "zipp                              3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a65a445f-c91f-4341-a023-baeb66118325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_object(obj):\n",
    "    for attribute in dir(obj):\n",
    "        if not attribute.startswith(\"__\"): # Avoid special methods\n",
    "            try:\n",
    "                value = getattr(obj, attribute)\n",
    "                print(f\"{attribute}: {value}\")\n",
    "            except AttributeError:\n",
    "                print(f\"{attribute}: <not accessible>\") # Handle potential errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00ea6784-6378-4d46-aff3-889ba2ab49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model_path = \"ibm-granite/granite-embedding-30m-english\"\n",
    "sparse_embeddings_model_path = \"ibm-granite/granite-embedding-30m-sparse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0691467c-1b74-4630-a8f6-eea914124f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2691d5823464734b9ede2d8cb544dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d7eccccd014cc9a1c7b125d4c25cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded4c7f5b57b40fba422e0d7ea29def5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48671115000e4eef86bd8a9594087040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c36db43dae5491b8d8549b5e23da8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_path)\n",
    "sparse_embeddings_tokenizer = AutoTokenizer.from_pretrained(sparse_embeddings_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3b0ec2a-cdaf-42c2-ab30-24249370ad4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df8fa1186a146ac97b508d965ac6da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = config = AutoConfig.from_pretrained(embeddings_model_path)\n",
    "sparse_config = AutoConfig.from_pretrained(sparse_embeddings_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de445c03-471f-4a8a-9e0f-76f5184c143f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_dict: True\n",
      "output_hidden_states: False\n",
      "output_attentions: False\n",
      "torchscript: False\n",
      "torch_dtype: torch.bfloat16\n",
      "use_bfloat16: False\n",
      "tf_legacy_loss: False\n",
      "pruned_heads: {}\n",
      "tie_word_embeddings: True\n",
      "chunk_size_feed_forward: 0\n",
      "is_encoder_decoder: False\n",
      "is_decoder: False\n",
      "cross_attention_hidden_size: None\n",
      "add_cross_attention: False\n",
      "tie_encoder_decoder: False\n",
      "max_length: 20\n",
      "min_length: 0\n",
      "do_sample: False\n",
      "early_stopping: False\n",
      "num_beams: 1\n",
      "num_beam_groups: 1\n",
      "diversity_penalty: 0.0\n",
      "temperature: 1.0\n",
      "top_k: 50\n",
      "top_p: 1.0\n",
      "typical_p: 1.0\n",
      "repetition_penalty: 1.0\n",
      "length_penalty: 1.0\n",
      "no_repeat_ngram_size: 0\n",
      "encoder_no_repeat_ngram_size: 0\n",
      "bad_words_ids: None\n",
      "num_return_sequences: 1\n",
      "output_scores: False\n",
      "return_dict_in_generate: False\n",
      "forced_bos_token_id: None\n",
      "forced_eos_token_id: None\n",
      "remove_invalid_values: False\n",
      "exponential_decay_length_penalty: None\n",
      "suppress_tokens: None\n",
      "begin_suppress_tokens: None\n",
      "architectures: ['RobertaModel']\n",
      "finetuning_task: None\n",
      "id2label: {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "label2id: {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "tokenizer_class: None\n",
      "prefix: None\n",
      "bos_token_id: 0\n",
      "pad_token_id: 1\n",
      "eos_token_id: 2\n",
      "sep_token_id: None\n",
      "decoder_start_token_id: None\n",
      "task_specific_params: None\n",
      "problem_type: None\n",
      "_name_or_path: ibm-granite/granite-embedding-30m-english\n",
      "_commit_hash: 2d1e2680423da61834c5edbaad2ff74624d0a9b0\n",
      "_attn_implementation_internal: None\n",
      "_attn_implementation_autoset: False\n",
      "transformers_version: 4.15.0\n",
      "model_type: roberta\n",
      "vocab_size: 50265\n",
      "hidden_size: 384\n",
      "num_hidden_layers: 6\n",
      "num_attention_heads: 12\n",
      "hidden_act: gelu\n",
      "intermediate_size: 1536\n",
      "hidden_dropout_prob: 0.1\n",
      "attention_probs_dropout_prob: 0.1\n",
      "max_position_embeddings: 514\n",
      "type_vocab_size: 2\n",
      "initializer_range: 0.02\n",
      "layer_norm_eps: 1e-12\n",
      "position_embedding_type: absolute\n",
      "use_cache: True\n",
      "classifier_dropout: None\n"
     ]
    }
   ],
   "source": [
    "dump_obj(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8940a2ec-6bfc-42ef-9ba1-deaebb852ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_dict: True\n",
      "output_hidden_states: False\n",
      "output_attentions: False\n",
      "torchscript: False\n",
      "torch_dtype: torch.bfloat16\n",
      "use_bfloat16: False\n",
      "tf_legacy_loss: False\n",
      "pruned_heads: {}\n",
      "tie_word_embeddings: True\n",
      "chunk_size_feed_forward: 0\n",
      "is_encoder_decoder: False\n",
      "is_decoder: False\n",
      "cross_attention_hidden_size: None\n",
      "add_cross_attention: False\n",
      "tie_encoder_decoder: False\n",
      "max_length: 20\n",
      "min_length: 0\n",
      "do_sample: False\n",
      "early_stopping: False\n",
      "num_beams: 1\n",
      "num_beam_groups: 1\n",
      "diversity_penalty: 0.0\n",
      "temperature: 1.0\n",
      "top_k: 50\n",
      "top_p: 1.0\n",
      "typical_p: 1.0\n",
      "repetition_penalty: 1.0\n",
      "length_penalty: 1.0\n",
      "no_repeat_ngram_size: 0\n",
      "encoder_no_repeat_ngram_size: 0\n",
      "bad_words_ids: None\n",
      "num_return_sequences: 1\n",
      "output_scores: False\n",
      "return_dict_in_generate: False\n",
      "forced_bos_token_id: None\n",
      "forced_eos_token_id: None\n",
      "remove_invalid_values: False\n",
      "exponential_decay_length_penalty: None\n",
      "suppress_tokens: None\n",
      "begin_suppress_tokens: None\n",
      "architectures: ['RobertaForMaskedLM']\n",
      "finetuning_task: None\n",
      "id2label: {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "label2id: {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "tokenizer_class: None\n",
      "prefix: None\n",
      "bos_token_id: 0\n",
      "pad_token_id: 1\n",
      "eos_token_id: 2\n",
      "sep_token_id: None\n",
      "decoder_start_token_id: None\n",
      "task_specific_params: None\n",
      "problem_type: None\n",
      "_name_or_path: ibm-granite/granite-embedding-30m-sparse\n",
      "_commit_hash: de282e89b5f3369c9321322be947f1e04182a1ad\n",
      "_attn_implementation_internal: None\n",
      "_attn_implementation_autoset: False\n",
      "transformers_version: 4.48.2\n",
      "model_type: roberta\n",
      "vocab_size: 50265\n",
      "hidden_size: 384\n",
      "num_hidden_layers: 6\n",
      "num_attention_heads: 12\n",
      "hidden_act: gelu\n",
      "intermediate_size: 1536\n",
      "hidden_dropout_prob: 0.1\n",
      "attention_probs_dropout_prob: 0.1\n",
      "max_position_embeddings: 514\n",
      "type_vocab_size: 2\n",
      "initializer_range: 0.02\n",
      "layer_norm_eps: 1e-12\n",
      "position_embedding_type: absolute\n",
      "use_cache: True\n",
      "classifier_dropout: None\n"
     ]
    }
   ],
   "source": [
    "dump_obj(sparse_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "641feec5-82fc-4d6b-82bf-1286b5bc9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(embeddings_model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2039a76-7a96-4f05-bfc3-a940a8f3c400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d7819962454ed3b113ad9e122cafc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/60.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparse_model = AutoModelForMaskedLM.from_pretrained(sparse_embeddings_model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a38b9c83-1345-42e3-b41a-5e2c4a0be713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   0,  713,   16,   10, 7728, 3645,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sample sentence.\"\n",
    "tokenized_input = sparse_embeddings_tokenizer(text, return_tensors=\"pt\") #  or tokenizer(text)\n",
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f44ad3f-8089-4903-8981-5c765b02993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0917,  0.6270,  0.2908,  ...,  0.8090, -7.7908,  0.4029],\n",
       "         [-0.9681,  0.4096,  1.1218,  ...,  1.9385, -8.3621, -1.2195],\n",
       "         [-0.6250,  0.4209,  1.2987,  ...,  2.0155, -8.8782, -1.3207],\n",
       "         ...,\n",
       "         [-0.7753,  0.2901,  1.3131,  ...,  1.8260, -7.9409, -1.2732],\n",
       "         [-0.7346,  0.1128,  0.9503,  ...,  1.8745, -8.2791, -1.2013],\n",
       "         [-1.1832,  0.1630,  0.9972,  ...,  1.6418, -8.7131, -1.3595]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0740, -0.3853, -0.3833,  0.8431,  0.8284, -0.5442,  0.0567, -0.7814,\n",
       "         -0.0306, -0.7020, -0.5249,  0.8708,  0.2952,  0.2342, -0.1667, -0.3459,\n",
       "          0.9935,  0.2066,  0.4474, -0.2957,  0.6336, -0.9835, -0.0151,  0.6406,\n",
       "          0.3330, -0.7784,  0.4974, -0.1368,  0.8830,  0.9333, -0.8930, -0.5642,\n",
       "         -0.9814, -0.4812, -0.2500,  0.5129,  0.2521,  0.2317,  0.2613, -0.5998,\n",
       "         -0.8011,  0.3829,  0.3943,  0.6421, -0.0899,  0.7475, -0.1785, -0.0082,\n",
       "         -0.2771,  0.1523,  0.6424,  0.6257,  0.7996, -0.1977,  0.5179,  0.1304,\n",
       "          0.9779, -0.2864, -0.1211,  0.9259, -0.0719,  0.8690,  0.7548, -0.1245,\n",
       "          0.4945, -0.6909, -0.7082,  0.7972,  0.3037, -0.1003, -0.9856, -0.7336,\n",
       "          0.9263,  0.9256, -0.8884, -0.9517,  0.9198, -0.2218, -0.6007, -0.2623,\n",
       "          0.0354, -0.2350, -0.6265, -0.4618,  0.0776, -0.6907, -0.3646, -0.6589,\n",
       "         -0.9870,  0.1958, -0.0291, -0.1279, -0.4441,  0.9904, -0.3208,  0.8392,\n",
       "          0.8351,  0.9643, -0.4190, -0.9130, -0.6051, -0.1850,  0.8151,  0.6643,\n",
       "          0.2722,  0.4669,  0.3551, -0.7673,  0.7879,  0.7449,  0.0866, -0.6874,\n",
       "         -0.7979,  0.1803, -0.9675,  0.4199,  0.5971, -0.4924, -0.8776,  0.7409,\n",
       "         -0.2957, -0.6598, -0.2154,  0.8744,  0.4743,  0.4758, -0.7111,  0.7325,\n",
       "         -0.0569, -0.9180, -0.7966, -0.7318,  0.6431,  0.6225,  0.1282,  0.9302,\n",
       "          0.7044,  0.7727, -0.9225, -0.5873,  0.2262, -0.6574, -0.7665,  0.2256,\n",
       "         -0.2621, -0.1845, -0.7267, -0.2174, -0.8375, -0.4397, -0.0468, -0.2357,\n",
       "         -0.4930,  0.8122, -0.0078,  0.1542, -0.1248,  0.8483,  0.3772,  0.4835,\n",
       "         -0.1310, -0.7915, -0.4309,  0.6175, -0.6895,  0.8280, -0.5300, -0.4154,\n",
       "          0.8591, -0.8797, -0.0159,  0.8889,  0.1511,  0.4267,  0.9700,  0.1359,\n",
       "         -0.6698,  0.9232,  0.3406, -0.7900, -0.4410,  0.5936,  0.9201, -0.7189,\n",
       "         -0.1394,  0.1477, -0.9965,  0.9823,  0.1406, -0.2418,  0.5606,  0.5792,\n",
       "         -0.8042, -0.4254,  0.6052, -0.4595, -0.2502, -0.9520,  0.2197, -0.4823,\n",
       "          0.5170,  0.8091, -0.3879, -0.4639, -0.8260, -0.4458,  0.9609, -0.0692,\n",
       "         -0.0043,  0.1441,  0.5697, -0.8067, -0.2069, -0.4326,  0.8798,  0.1013,\n",
       "          0.1984,  0.6573,  0.1543, -0.2530,  0.6836,  0.5762, -0.5490, -0.5002,\n",
       "          0.2256,  0.8929,  0.4125, -0.9108, -0.8501,  0.8949, -0.9295,  0.7267,\n",
       "          0.6709, -0.2730, -0.9782,  0.2977,  0.0281, -0.6427,  0.6617,  0.3264,\n",
       "          0.6242,  0.0778,  0.4898,  0.4216,  0.0653, -0.7917,  0.7115, -0.8953,\n",
       "         -0.1242,  0.6717,  0.8041, -0.2524,  0.8982,  0.0334, -0.7311,  0.8276,\n",
       "         -0.4789, -0.1192,  0.6921,  0.3642,  0.9173, -0.3858,  0.2192,  0.6478,\n",
       "         -0.9039, -0.9603,  0.3174,  0.4122,  0.0102, -0.9031, -0.4773, -0.9203,\n",
       "         -0.9711,  0.2491,  0.5398,  0.1465,  0.7731, -0.3636,  0.0856, -0.9249,\n",
       "         -0.9402, -0.8143,  0.9617, -0.9236,  0.4501,  0.6816, -0.6817, -0.4293,\n",
       "         -0.7997,  0.4914, -0.4586, -0.7421,  0.8378,  0.5533,  0.4648,  0.7744,\n",
       "         -0.2198, -0.6546, -0.6248, -0.8976, -0.7265,  0.2899,  0.2204,  0.4683,\n",
       "         -0.8662,  0.9477,  0.9595, -0.7102,  0.0213, -0.2854, -0.7403, -0.5611,\n",
       "          0.4109,  0.5524, -0.7081, -0.7135,  0.7712,  0.4315,  0.1582, -0.7147,\n",
       "         -0.8564,  0.7984, -0.9056, -0.2025, -0.7665, -0.9329,  0.1605,  0.6742,\n",
       "         -0.8143, -0.2203, -0.5210,  0.4447, -0.9348, -0.5459,  0.9094, -0.5407,\n",
       "          0.0126, -0.3886, -0.4366,  0.2024, -0.6587,  0.5162, -0.6502, -0.9549,\n",
       "         -0.2265, -0.4854, -0.9864,  0.7529, -0.3086,  0.6014, -0.1915, -0.0193,\n",
       "         -0.9411,  0.8741,  0.9820, -0.9875, -0.7178, -0.0633, -0.8672,  0.4341,\n",
       "          0.3395,  0.9306,  0.3395,  0.3136,  0.5801,  0.7918,  0.9851, -0.2711,\n",
       "         -0.9076,  0.7507, -0.0567, -0.8593,  0.6922,  0.9583,  0.1962,  0.8044,\n",
       "          0.2990, -0.5986,  0.3657,  0.9466,  0.9195, -0.5041,  0.3108, -0.8859]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(**tokenized_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e97f884-8782-4e9d-9c1f-592398d82be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "daef3e66-bac7-4a86-a467-b0f61e25153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_hidden_state: tensor([[[ 0.0917,  0.6270,  0.2908,  ...,  0.8090, -7.7908,  0.4029],\n",
      "         [-0.9681,  0.4096,  1.1218,  ...,  1.9385, -8.3621, -1.2195],\n",
      "         [-0.6250,  0.4209,  1.2987,  ...,  2.0155, -8.8782, -1.3207],\n",
      "         ...,\n",
      "         [-0.7753,  0.2901,  1.3131,  ...,  1.8260, -7.9409, -1.2732],\n",
      "         [-0.7346,  0.1128,  0.9503,  ...,  1.8745, -8.2791, -1.2013],\n",
      "         [-1.1832,  0.1630,  0.9972,  ...,  1.6418, -8.7131, -1.3595]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "pooler_output: tensor([[ 0.0740, -0.3853, -0.3833,  0.8431,  0.8284, -0.5442,  0.0567, -0.7814,\n",
      "         -0.0306, -0.7020, -0.5249,  0.8708,  0.2952,  0.2342, -0.1667, -0.3459,\n",
      "          0.9935,  0.2066,  0.4474, -0.2957,  0.6336, -0.9835, -0.0151,  0.6406,\n",
      "          0.3330, -0.7784,  0.4974, -0.1368,  0.8830,  0.9333, -0.8930, -0.5642,\n",
      "         -0.9814, -0.4812, -0.2500,  0.5129,  0.2521,  0.2317,  0.2613, -0.5998,\n",
      "         -0.8011,  0.3829,  0.3943,  0.6421, -0.0899,  0.7475, -0.1785, -0.0082,\n",
      "         -0.2771,  0.1523,  0.6424,  0.6257,  0.7996, -0.1977,  0.5179,  0.1304,\n",
      "          0.9779, -0.2864, -0.1211,  0.9259, -0.0719,  0.8690,  0.7548, -0.1245,\n",
      "          0.4945, -0.6909, -0.7082,  0.7972,  0.3037, -0.1003, -0.9856, -0.7336,\n",
      "          0.9263,  0.9256, -0.8884, -0.9517,  0.9198, -0.2218, -0.6007, -0.2623,\n",
      "          0.0354, -0.2350, -0.6265, -0.4618,  0.0776, -0.6907, -0.3646, -0.6589,\n",
      "         -0.9870,  0.1958, -0.0291, -0.1279, -0.4441,  0.9904, -0.3208,  0.8392,\n",
      "          0.8351,  0.9643, -0.4190, -0.9130, -0.6051, -0.1850,  0.8151,  0.6643,\n",
      "          0.2722,  0.4669,  0.3551, -0.7673,  0.7879,  0.7449,  0.0866, -0.6874,\n",
      "         -0.7979,  0.1803, -0.9675,  0.4199,  0.5971, -0.4924, -0.8776,  0.7409,\n",
      "         -0.2957, -0.6598, -0.2154,  0.8744,  0.4743,  0.4758, -0.7111,  0.7325,\n",
      "         -0.0569, -0.9180, -0.7966, -0.7318,  0.6431,  0.6225,  0.1282,  0.9302,\n",
      "          0.7044,  0.7727, -0.9225, -0.5873,  0.2262, -0.6574, -0.7665,  0.2256,\n",
      "         -0.2621, -0.1845, -0.7267, -0.2174, -0.8375, -0.4397, -0.0468, -0.2357,\n",
      "         -0.4930,  0.8122, -0.0078,  0.1542, -0.1248,  0.8483,  0.3772,  0.4835,\n",
      "         -0.1310, -0.7915, -0.4309,  0.6175, -0.6895,  0.8280, -0.5300, -0.4154,\n",
      "          0.8591, -0.8797, -0.0159,  0.8889,  0.1511,  0.4267,  0.9700,  0.1359,\n",
      "         -0.6698,  0.9232,  0.3406, -0.7900, -0.4410,  0.5936,  0.9201, -0.7189,\n",
      "         -0.1394,  0.1477, -0.9965,  0.9823,  0.1406, -0.2418,  0.5606,  0.5792,\n",
      "         -0.8042, -0.4254,  0.6052, -0.4595, -0.2502, -0.9520,  0.2197, -0.4823,\n",
      "          0.5170,  0.8091, -0.3879, -0.4639, -0.8260, -0.4458,  0.9609, -0.0692,\n",
      "         -0.0043,  0.1441,  0.5697, -0.8067, -0.2069, -0.4326,  0.8798,  0.1013,\n",
      "          0.1984,  0.6573,  0.1543, -0.2530,  0.6836,  0.5762, -0.5490, -0.5002,\n",
      "          0.2256,  0.8929,  0.4125, -0.9108, -0.8501,  0.8949, -0.9295,  0.7267,\n",
      "          0.6709, -0.2730, -0.9782,  0.2977,  0.0281, -0.6427,  0.6617,  0.3264,\n",
      "          0.6242,  0.0778,  0.4898,  0.4216,  0.0653, -0.7917,  0.7115, -0.8953,\n",
      "         -0.1242,  0.6717,  0.8041, -0.2524,  0.8982,  0.0334, -0.7311,  0.8276,\n",
      "         -0.4789, -0.1192,  0.6921,  0.3642,  0.9173, -0.3858,  0.2192,  0.6478,\n",
      "         -0.9039, -0.9603,  0.3174,  0.4122,  0.0102, -0.9031, -0.4773, -0.9203,\n",
      "         -0.9711,  0.2491,  0.5398,  0.1465,  0.7731, -0.3636,  0.0856, -0.9249,\n",
      "         -0.9402, -0.8143,  0.9617, -0.9236,  0.4501,  0.6816, -0.6817, -0.4293,\n",
      "         -0.7997,  0.4914, -0.4586, -0.7421,  0.8378,  0.5533,  0.4648,  0.7744,\n",
      "         -0.2198, -0.6546, -0.6248, -0.8976, -0.7265,  0.2899,  0.2204,  0.4683,\n",
      "         -0.8662,  0.9477,  0.9595, -0.7102,  0.0213, -0.2854, -0.7403, -0.5611,\n",
      "          0.4109,  0.5524, -0.7081, -0.7135,  0.7712,  0.4315,  0.1582, -0.7147,\n",
      "         -0.8564,  0.7984, -0.9056, -0.2025, -0.7665, -0.9329,  0.1605,  0.6742,\n",
      "         -0.8143, -0.2203, -0.5210,  0.4447, -0.9348, -0.5459,  0.9094, -0.5407,\n",
      "          0.0126, -0.3886, -0.4366,  0.2024, -0.6587,  0.5162, -0.6502, -0.9549,\n",
      "         -0.2265, -0.4854, -0.9864,  0.7529, -0.3086,  0.6014, -0.1915, -0.0193,\n",
      "         -0.9411,  0.8741,  0.9820, -0.9875, -0.7178, -0.0633, -0.8672,  0.4341,\n",
      "          0.3395,  0.9306,  0.3395,  0.3136,  0.5801,  0.7918,  0.9851, -0.2711,\n",
      "         -0.9076,  0.7507, -0.0567, -0.8593,  0.6922,  0.9583,  0.1962,  0.8044,\n",
      "          0.2990, -0.5986,  0.3657,  0.9466,  0.9195, -0.5041,  0.3108, -0.8859]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "hidden_states: None\n",
      "past_key_values: None\n",
      "attentions: None\n",
      "cross_attentions: None\n"
     ]
    }
   ],
   "source": [
    "dump_obj(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158b8c5-5289-429f-8e54-3c5276749ba7",
   "metadata": {},
   "source": [
    "from HF Transformers: [transformers/src/transformers modeling_outputs.py](https://github.com/huggingface/transformers/blob/main/src/transformers/modeling_outputs.py#L70)\n",
    "```\n",
    "class BaseModelOutputWithPooling(ModelOutput):\n",
    "...\n",
    "last_hidden_state (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n",
    "    Sequence of hidden-states at the output of the last layer of the model.\n",
    "pooler_output (`torch.FloatTensor` of shape `(batch_size, hidden_size)`):\n",
    "    Last layer hidden-state of the first token of the sequence (classification token) after further processing\n",
    "    through the layers used for the auxiliary pretraining task. E.g. for BERT-family of models, this returns\n",
    "    the classification token after processing through a linear layer and a tanh activation function (The tanh\n",
    "    function outputs values in the range of -1 to +1). \n",
    "    The linear layer weights are trained from the next sentence prediction (classification) objective during\n",
    "    pretraining.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab769b1-fab9-47c9-b8e8-62b247c48a1d",
   "metadata": {},
   "source": [
    "Understanding shapes from PyTorch: \n",
    "- [Tensor Shapes](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html#tensor-shapes)\n",
    "- [torch.Tensor.shape](https://pytorch.org/docs/stable/generated/torch.Tensor.shape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a13d8780-5785-4836-a9c1-ba0469a463d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 384])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ([rows, num_rows (matches input tokens), columns (sequence_length)])\n",
    "# contains: logits (un-normalized values)\n",
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65121892-f669-4454-a746-136966e203c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ([rows, sequence_length])\n",
    "# containst: embeddings (normlized, using tanh fx.)\n",
    "output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95bde0-d49f-42c2-9c93-7c1b921eb806",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
